{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 2.4相知篇-张量操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔲能今天做好的事就不要等到明天。以梦为马，学习趁年华"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量（Tensor）是Tensorflow的基本操作对象，可以看做是包含单一数据类型元素的多维矩阵。图像的实质是多维张量，对张量的认识和使用是我们开始深度学习的第一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、本节目标\n",
    "   本节将详述概述张量的基本操作包括张量的索引与切片、张量维度的变换、张量的分割与合并等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 张量操作示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 索引与切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 索引\n",
    "索引操作比较简单，直接通过维度编号进行索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "# 创建2维张量\n",
    "t = tf.constant([[1,2,3,4,5],[6,7,8,9,10]]) \n",
    "# 取0维度上的第一组数据\n",
    "a = t[0]  \n",
    "# 即x[0]中的第二组数据\n",
    "b = t[0][1]   \n",
    "print(a)\n",
    "print('-'*50)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 切片\n",
    "切片采用[start : end : step]的方式。start:end为含头不含尾的切片操作，表示从start位开始，一直到end-1位结束；加入步长step后，从start到end-1间隔step取数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=16, shape=(2,), dtype=int32, numpy=array([6, 8])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 先取0维度第二组数据:[6,7,8,9,10]，再从[6 7 8 9]中间隔2取数据\n",
    "t[1,0:4:2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2维度变换\n",
    "基本的维度变换包含改变视图的tf.reshape，插入新维度tf.expand_dims，删除维度tf.squeeze，交换维度tf.transpose等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 tf.Reshape\n",
    "tf.reshape(tensor, shape, name=None)\n",
    "第一个参数为被调整维度的张量，第二个参数为要调整为的形状，返回一个shape形状的新rensor。shape里最多有一个维度的值可以为-1，表示自动计算此维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]\n",
      "  [ 9 10 11]]\n",
      "\n",
      " [[12 13 14]\n",
      "  [15 16 17]\n",
      "  [18 19 20]\n",
      "  [21 22 23]]], shape=(2, 4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.range(24)\n",
    "t1 = tf.reshape(t, [2, 4, 3])\n",
    "print(t)\n",
    "print('-'*50)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 tf.expand_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tf.expand_dims(input, axis)可在指定的axis轴前插入一个新的维度。aixs为正时，表示在当前维度之前插入一个新的维度，为负时，表示在当前维度之后插入一个新的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]], shape=(1, 2, 3), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[4 5 6]]], shape=(2, 1, 3), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[4]\n",
      "  [5]\n",
      "  [6]]], shape=(2, 3, 1), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[4]\n",
      "  [5]\n",
      "  [6]]], shape=(2, 3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = [[1, 2, 3],[4, 5, 6]]            #shape [2,3]\n",
    "t1 = tf.expand_dims(t, axis = 0)     #sahpe [1,2,3]\n",
    "t2 = tf.expand_dims(t, axis = 1)     #shape [2,,1,3]\n",
    "t3 = tf.expand_dims(t, axis = 2)     #shape [2,3,1]\n",
    "t4 = tf.expand_dims(t, axis = -1)    #shape [2,3,1]\n",
    "print(t1)\n",
    "print('-'*50)\n",
    "print(t2)\n",
    "print('-'*50)\n",
    "print(t3)\n",
    "print('-'*50)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 tf.squeeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tf.squeeze(input, axis)可以删除长度为1的维度，axis参数为待删除维度的索引号，删除维度只能删除长度为1的维度，如果不指定维度参数axis，即tf.sequeeze(input)，则其会默认删除所有长度为1的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[[0]\n",
      "    [1]\n",
      "    [2]]]\n",
      "\n",
      "\n",
      "  [[[3]\n",
      "    [4]\n",
      "    [5]]]]], shape=(1, 2, 1, 3, 1), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.range(6)   # [0 1 2 3 4 5]\n",
    "t1 = tf.reshape(t, [1,2,1,3,1])\n",
    "t2 = tf.squeeze(t1)\n",
    "print(t1)\n",
    "print('-'*50)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4tf.transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交换维度操作是十分常见的,可以通过tf.transpose(x, perm)函数完成维度交换操作，其中perm表示新维度的顺序List。考虑图片张量shape为[2, 5, 5, 3]，图片数量、行、列、通道数的维度索引为[0, 1, 2, 3]，将其交换为[b, c, h, w]格式，则新维度的索引号为[0, 3, 1, 2]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "t = tf.random.normal([2, 5, 5, 3])   #sahpe [2, 5, 5, 3]\n",
    "t1 = tf.transpose(t, perm = [0, 3, 1, 2])\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 合并与分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 合并\n",
    "合并是指将多个张量沿某个维度合并为一个张量。按照是否产生新的维度，张量合并分为张量拼接（concatenate)和张量堆叠(stack)。\n",
    "张量拼接在Tensorflow中通过tf.concat(tensors,axis)实现，其中tensors为list,每个元素为一个需要合并的张量，axis为需要合并的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]], shape=(4, 3), dtype=int32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  7  8  9]\n",
      " [ 4  5  6 10 11 12]], shape=(2, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "b = tf.constant([[7, 8, 9], [10, 11, 12]])\n",
    "c1 = tf.concat([a, b], 0)\n",
    "c2 = tf.concat([a, b], 1)\n",
    "print(c1)   # 未产生新维度\n",
    "print('-'*50)\n",
    "print(c2)   # 未产生新维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是：张量合并在非合并维度的长度必须一致。\n",
    "张量堆叠会产生新的维度，通过tf.stack(tensors, axis) 实现，tensors为可以合并的多个张量，axis 指定插入新维度的位 置。当axis ≥ 0时，在 axis 之前插入;当axis < 0时， 在 axis 之后插入新维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=64, shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "b = tf.constant([[7, 8, 9], [10, 11, 12]])\n",
    "tf.stack([a, b])   # axis默认为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是：需要合并的张量 shape 完全一致才可堆叠，否则会出现错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)tf.unstack**\n",
    "\n",
    "tf.unstack(tensor, num, axis)，tf.unstack()将tensor根据axis分解成num个张量，返回的值是list类型，如果没有指定num则根据axis推断出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=67, shape=(5,), dtype=int32, numpy=array([3, 2, 4, 5, 6])>, <tf.Tensor: id=68, shape=(5,), dtype=int32, numpy=array([1, 6, 7, 8, 0])>]\n",
      "--------------------------------------------------\n",
      "[<tf.Tensor: id=69, shape=(2,), dtype=int32, numpy=array([3, 1])>, <tf.Tensor: id=70, shape=(2,), dtype=int32, numpy=array([2, 6])>, <tf.Tensor: id=71, shape=(2,), dtype=int32, numpy=array([4, 7])>, <tf.Tensor: id=72, shape=(2,), dtype=int32, numpy=array([5, 8])>, <tf.Tensor: id=73, shape=(2,), dtype=int32, numpy=array([6, 0])>]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3,2,4,5,6],[1,6,7,8,0]])\n",
    "b = tf.constant([[3,1],[2,6],[4,7],[5,8],[6,0]])\n",
    "c = tf.unstack(a,axis=0)\n",
    "d = tf.unstack(a,axis=1)\n",
    "print(c)\n",
    "print('-'*50)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)tf.split**  \n",
    "\n",
    "tf.split(tensor, num_or_size_splits, axis),tensor为待分割张量，num_or_size_splits控制分割后对应维度上元素的个数，axis为指定分割的维度索引号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=77, shape=(2, 1), dtype=int32, numpy=\n",
       " array([[1],\n",
       "        [4]])>,\n",
       " <tf.Tensor: id=78, shape=(2, 1), dtype=int32, numpy=\n",
       " array([[2],\n",
       "        [5]])>,\n",
       " <tf.Tensor: id=79, shape=(2, 1), dtype=int32, numpy=\n",
       " array([[3],\n",
       "        [6]])>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,3],[4,5,6]]\n",
    "tf.split(x, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 范数\n",
    "范数(Vector norm)是表征向量“长度”的一种度量方法，在神经网络中，常用来 表示张量的权值大小，梯度大小等。常用的范数有：L1 范数、L2 范数、∞ −范数。在 TensorFlow 中，可以通过 tf.norm(x, ord)求解张量的 L1, L2, ∞等范数，其中参数 ord 指定为 1,2 时计算 L1, L2 范数，指定为 np.inf 时计算∞ −范数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm is: 9.0\n",
      "L2 norm is: 3.0\n",
      "∞ norm is: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=tf.ones([3,3])\n",
    "# L1 范数 \n",
    "L1=tf.norm(x,ord=1) \n",
    "print(\"L1 norm is: {}\".format(L1))\n",
    "# L2范数 \n",
    "L2=tf.norm(x,ord=2) \n",
    "print(\"L2 norm is: {}\".format(L2))\n",
    "# ∞范数 \n",
    "L_inf=tf.norm(x,ord=np.inf) \n",
    "print(\"∞ norm is: {}\".format(L_inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 最值、均值\n",
    "通过 tf.reduce_max, tf.reduce_min, tf.reduce_mean可以求取指定维度上的最大、最小和均值，也可求取全部数组中的最大、最小和均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is: [1.4482821 1.7981522 1.7702887]\n",
      "min is: [ 0.7384832 -1.0196708  1.0502723]\n",
      "mean is: [1.1128851  0.15834224 1.3904089 ]\n"
     ]
    }
   ],
   "source": [
    "#创建张量\n",
    "x = tf.random.normal([3,3])\n",
    "#统计最大值\n",
    "max=tf.reduce_max(x,axis=1)\n",
    "print(\"max is: {}\".format(max))\n",
    "#统计最小值\n",
    "min=tf.reduce_min(x,axis=1)\n",
    "print(\"min is: {}\".format(min))\n",
    "# 统计均值 \n",
    "mean=tf.reduce_mean(x,axis=1) \n",
    "print(\"mean is: {}\".format(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当不指定 axis 参数时，tf.reduce_*函数会求解出全局元素的最大、最小、均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max is: 1.1456173658370972\n",
      "min is: -1.5715750455856323\n",
      "mean is: -0.3301786184310913\n"
     ]
    }
   ],
   "source": [
    "#创建张量\n",
    "x = tf.random.normal([3,3])\n",
    "#统计最大值\n",
    "max=tf.reduce_max(x)\n",
    "print(\"max is: {}\".format(max))\n",
    "#统计最小值\n",
    "min=tf.reduce_min(x)\n",
    "print(\"min is: {}\".format(min))\n",
    "# 统计均值 \n",
    "mean=tf.reduce_mean(x) \n",
    "print(\"mean is: {}\".format(mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 张量比较\n",
    "在深度学习中，通常需要将预测结果与真实标签进行比较，从而计算准确率。常用的张量比较函数有以下几种："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161598288123372391615982880142.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下以tf.equal(a,b)为例说明其用法。\n",
    "tf.equal()函数返回布尔型的张量比较结果，通过统计张量中True元素的个数即可获得预测正确的数量。一般情况下，我们先将布尔型转换为整型张量0和1，再求和即可得到1的个数，也就是True元素的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is: [[ True False  True  True  True  True False  True  True False  True  True\n",
      "  False  True False  True]]\n",
      "correct is: 11.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pre_out=tf.convert_to_tensor(np.array([[1,2,3,4,2,3,5,6,7,8,9,2,3,4,5,4]])) \n",
    "label=tf.convert_to_tensor(np.array([[1,7,3,4,2,3,4,6,7,3,9,2,7,4,2,4]])) \n",
    "# 预测值与真实值比较 \n",
    "acc=tf.equal(pre_out,label) \n",
    "print(\"acc is: {}\".format(acc))\n",
    " # 布尔型转 int 型\n",
    "acc = tf.cast(acc, dtype=tf.float32)\n",
    "# 统计 True 的个数 \n",
    "correct = tf.reduce_sum(acc)\n",
    "print(\"correct is: {}\".format(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其它的比较运算函数请读者自行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 填充和复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1 填充\n",
    "f.pad(tensor,paddings,mode=\"CONSTANT\",constant_values=0)主要是用来对tensor的大小进行扩展，包括水平、垂直、深度等,tensor为输入的张量，paddings为设置填充的大小，mode为填充方式（可选择CONSTANT、REFLECT和SYMMETRIC，默认是CONSTANT）,constant_values为CONSTANT填充方式的填充值，默认为0，当填充方式为REFLECT和SYMMETRIC时，constant_values无效，使用tensor中的值进行填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=142, shape=(5, 7), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 2, 2, 2, 0, 0],\n",
       "       [0, 0, 2, 2, 2, 0, 0],\n",
       "       [0, 0, 2, 2, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.fill([3,3],2)\n",
    "# 第一维度，前面补一维度，后面补一维度；第二维度，前面补两维度，后面补两维度。\n",
    "tf.pad(a,[[1,1],[2,2]])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.2 复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过tf.tile(tensor, multiples)函数完成数据在指定维度上的复制操作，multiples分别指定了每个维度上的复制倍数，对应位置为1表明不复制，为2表明新长度为原来长度的2倍，即数据复制一份，以此类推。\n",
    "如下，通过tf.tile(x, multiples=[2, 1])可以在axis = 0维度复制一次，在axis=1维度不复制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=145, shape=(4, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4]])\n",
    "# 在axis=0维度复制一次，在axis=1维度不复制。\n",
    "tf.tile(a, multiples=[2, 1])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 数据限幅操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过简单的数据限幅运算可以限制数据的范围，在Tensorflow中，通过tf.maximum(x,a)实现数据的下限幅：x ∈ [𝑎,+∞)；通过 tf.minimum(x, a)实现数据的上幅限制：𝑥 ∈（-∞，a]  。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=151, shape=(100,), dtype=int32, numpy=\n",
       "array([50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.range(100)\n",
    "#下限幅 50\n",
    "tf.maximum(x,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=153, shape=(100,), dtype=int32, numpy=\n",
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 80, 80, 80, 80,\n",
       "       80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#上限幅80\n",
    "tf.minimum(x,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过组合 tf.maximum(x, a)和 tf.minimum(x, b)可以实现同时对数据的上下边界限幅： 𝑥 ∈ [𝑎,𝑏]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=161, shape=(10,), dtype=int32, numpy=array([3, 3, 3, 3, 4, 5, 6, 7, 8, 8])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上下限幅为 \n",
    "x = tf.range(10) \n",
    "tf.minimum(tf.maximum(x,3),8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据限幅操作主要用在激活函数中，如relu函数中限制输出的上下限，读者可自行实现一下限幅relu激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "173219",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
