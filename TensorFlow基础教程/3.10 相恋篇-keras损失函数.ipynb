{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaptive-weight",
   "metadata": {},
   "source": [
    "#  📚 3.10 相恋篇-keras损失函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-imperial",
   "metadata": {},
   "source": [
    "         ✅能今天做好的事就不要等到明天。以梦为马，学习趁年华.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-philosophy",
   "metadata": {},
   "source": [
    "    损失函数（loss function），可以用来计算输出的结果（预测值）和我们期望的结果（标签）之间的差距，在神经网络的位置如图所示，接下来详细介绍每个函数的作用。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "spread-folder",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG963.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-science",
   "metadata": {},
   "source": [
    "# 一、本节目标\n",
    "        知道常用损失函数，知道在哪里可以找到损失函数，会自定义损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-burton",
   "metadata": {},
   "source": [
    "# 二、损失函数\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-trinidad",
   "metadata": {},
   "source": [
    "首先我们要知道损失函数在tensorflow2里面哪个位置，可以看到python3.7/site-packages/tensorflow/keras/losses目录下，"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "advanced-advertising",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG964.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-jerusalem",
   "metadata": {},
   "source": [
    "那么损失函数都有哪些呢，可以看到在tensorflow/keras/losses里面有以下损失函数，那么这些函数之间有哪些区别，具体有哪些呢？可以具体参考tensorflow官网。如果本机有tensorflow，可以直接找到"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dated-dubai",
   "metadata": {},
   "source": [
    "<img src=\"https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161611965570490791616119653388.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-kelly",
   "metadata": {},
   "source": [
    "\n",
    "那么在一个机器学习的过程中激活函数在tensorflow2框架中运用在哪个地方呢，\n",
    "那么损失函数在4.模型训练配置这里面可以使用，\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer 优化器\n",
    "    # Loss function to minimize 损失）\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor 指标\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")那么在tensorflow2.0中这些有哪些差别呢？其实只要懂其中一个损失函数就基本能够理解和使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-federal",
   "metadata": {},
   "source": [
    "## 2.1 均方差函数(mean_squared_error)\n",
    "     均方差误差(Mean Squared Error  MSE)函数把输出向量和真实向量映射到笛卡尔坐标系的两个点上，通过计算这两个点之间的欧式距离(准确地说是欧式距离的平方)来衡量两个向量之间的差距:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "framed-offering",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG966.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-charger",
   "metadata": {},
   "source": [
    " MSE 误差函数的值总是大于等于 0，当 MSE 函数达到最小值 0 时，输出等于真实标签， 此时神经网络的参数达到最优状态。均方差广泛应用在回归问题中，在分类问题中也可以应用均方差误差。在 TensorFlow中，可以通过函数方式或层方式实现 MSE 误差计算. 平方差误差损失，用于回归，简写为 mse, 类实现形式为 MeanSquaredError 和 MSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "military-reverse",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG967.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.1711771   0.39136323  0.59791994  1.1170292  -1.6079721   0.9971356\n",
      "   1.785494   -0.58000416 -0.07646657 -0.5593076 ]\n",
      " [-1.2421002  -0.45962852  0.4289117  -0.5964178  -0.42673147 -0.82051384\n",
      "  -0.24469914  0.6017577  -0.34494728  0.3556995 ]], shape=(2, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "o = tf.random.normal([2,10]) # 构造网络输出\n",
    "print(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bound-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]], shape=(2, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_onehot = tf.constant([1,3]) # 构造真实值 \n",
    "y_onehot = tf.one_hot(y_onehot, depth=10)\n",
    "print(y_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lightweight-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.0770277  0.60094297], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.mse(y_onehot, o) # 计算均方差  平方差误差损失，用于回归，简写为 mse, 类实现形式为 MeanSquaredError 和 MSE\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-columbia",
   "metadata": {},
   "source": [
    "## 2.2 交叉熵函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "hungarian-communist",
   "metadata": {},
   "source": [
    " <img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG968.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "narrative-pakistan",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG969.png\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "divine-daily",
   "metadata": {},
   "source": [
    "其中交叉熵的损失函数有以下三种，\n",
    "    • 1. sparse_categorical_crossentropy(稀疏类别交叉熵），类实现形式为 SparseCategoricalCrossentropy\n",
    "    • 2. categorical_crossentropy(多分类类别交叉熵，要求label为onehot编码，类实现形式为 CategoricalCrossentropy)\n",
    "    • 3. binary_crossentropy(二元交叉熵，用于二分类，类实现形式为 BinaryCrossentropy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "wireless-domain",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG970.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "hungarian-fever",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG971.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "compressed-wholesale",
   "metadata": {},
   "source": [
    "<img src=\"http://tianchi-media.oss-cn-beijing.aliyuncs.com/AIlearning/TensorFlow%E8%AF%BE%E7%A8%8B%E5%9B%BE%E7%89%87/%E7%9B%B8%E6%81%8B%E7%AF%87-keras%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/WechatIMG972.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outstanding-palestine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.05129331, 2.3025851 ], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "loss#可以自己试着计算，看结果 是否相等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-mileage",
   "metadata": {},
   "source": [
    "# 三、自定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-philosophy",
   "metadata": {},
   "source": [
    "    自定义损失函数只需要定义一个函数，并在compile的时候调用该自定义损失函数即可。损失函数有两个默认参数，分别为实际输出、预测输出，如果损失函数只需要这两个参数，那么设计起来就很方便。  \n",
    "    \n",
    "    自定义损失函数有两种情况，一种比较简单，只需要默认参数，不需要加入其它参数，而另一种参数稍显复杂，需要其他的一些参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-anxiety",
   "metadata": {},
   "source": [
    "## 3.1 只需要默认参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "toxic-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义损失函数\n",
    "def customized_mse(y_true, y_pred):\n",
    "    return (y_pred - y_true)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excellent-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decent-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "#编译compile\n",
    "model.compile(loss = customized_mse,   #使用自定义的损失函数\n",
    "             optimizer = \"sgd\", #优化函数\n",
    "              metrics = [\"mean_squared_error\"] #评价函数:用于评估当前训练模型的性能,评价函数和损失函数相似，只不过评价函数的结果不会用于训练过程中\n",
    "             ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-efficiency",
   "metadata": {},
   "source": [
    "## 3.2 需要额外的参数"
   ]
  },
  {
   "cell_type": "raw",
   "id": "nonprofit-earthquake",
   "metadata": {},
   "source": [
    "    损失函数需要的数据不止是预测值和真实值这么简单，比如我要添加一个权重的惩罚项以防权重过大，这时我们就需要引入额外的参数。只能自己自行设计模型运行自己的流程。可以将 tf.keras.losses.Loss 类子类化，并实现以下两个方法：\n",
    "    • __init__(self)：接受要在调用损失函数期间传递的参数\n",
    "    • call(self, y_true, y_pred)：使用目标 (y_true) 和模型预测 (y_pred) 来计算模型的损失。\n",
    "    假设您要使用均方误差，但存在一个会抑制预测值远离 0.5（我们假设分类目标采用独热编码，且取值介于 0 和 1 之间）的附加项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "certain-horse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 891us/step - loss: 0.0490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10f1d9490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-least",
   "metadata": {},
   "source": [
    "# 四、课后作业\n",
    "\n",
    "    1 认识其他的损失函数\n",
    "    2 会自定义损失和调用库中的损失"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
